Applied Machine Learning Models

This repository contains practical implementations of essential Machine Learning algorithms built using Python and scikit-learn.

The primary goal is to strengthen conceptual clarity through implementation. Each notebook focuses on applying algorithms to structured datasets, analyzing performance, and understanding how model choices affect results.

This repository emphasizes:

Real-world experimentation

Systematic feature selection

Model tuning and validation

Performance comparison

Proper evaluation techniques

üìÅ Project Structure

1Ô∏è‚É£ auto_mpg_backward_elimination.ipynb

Implements Linear Regression using a backward elimination strategy to identify the most relevant predictors.

What it demonstrates:

Removing features step-by-step based on statistical relevance

Validating model performance using cross-validation

Evaluating regression quality using R¬≤ score

Interpreting feature contribution

2Ô∏è‚É£ auto_mpg_forward_feature_selection.ipynb

Applies forward selection for building an optimized regression model.

What it demonstrates:

Incrementally adding features

Measuring improvement after each addition

Selecting the most impactful combination of variables

3Ô∏è‚É£ svm_grid_search.ipynb

Builds and tunes a Support Vector Machine classifier.

What it demonstrates:

Testing multiple kernel functions

Applying Grid Search for parameter optimization

Selecting the best model using cross-validation

Evaluating generalization performance

4Ô∏è‚É£ confusion_matrix_analysis.ipynb

Explores classification model evaluation techniques.

What it demonstrates:

Constructing and interpreting confusion matrices

Calculating Accuracy, Precision, Recall, and F1-score

Understanding different types of classification errors

Comparing model performance using multiple metrics

5Ô∏è‚É£ knn_breastcancer_implementation.ipynb

Implements K-Nearest Neighbors (KNN) for tumor classification using the Breast Cancer dataset.

What it demonstrates:

Loading and preparing the dataset

Splitting into training and testing sets

Training models with different values of K (1‚Äì7)

Comparing performance across multiple K values

Evaluating predictions using accuracy and confusion matrix

This notebook highlights how distance-based algorithms behave when the number of neighbors changes.

6Ô∏è‚É£ knn_categorical_job_prediction.ipynb

Applies KNN to a fully categorical dataset for predicting job selection outcomes.

Objective:
Determine whether a candidate receives a job offer (Yes/No) based on academic and skill-related attributes.

Attributes Used:

CGPA

Communication Skills

Aptitude

Professional Skills

Implementation Steps:

Import dataset from CSV

Convert target labels into binary format

Transform categorical features using One-Hot Encoding

Split data into training and testing subsets

Train KNN models with multiple K values (1‚Äì5)

Evaluate model performance using confusion matrix and accuracy

This notebook demonstrates how categorical data must be converted into numerical form before applying distance-based algorithms.

7Ô∏è‚É£ naivebayes_breastcancer_models.py

Implements three variations of Naive Bayes classification on the Breast Cancer Wisconsin dataset.

This script compares the performance of:

Multinomial Naive Bayes

Complement Naive Bayes

Bernoulli Naive Bayes

üìå Objective

Classify tumors as malignant or benign using probability-based classification methods and compare how different Naive Bayes variants perform on the same dataset.

‚öôÔ∏è Implementation Workflow

Load Breast Cancer dataset using load_breast_cancer

Split the dataset into training and testing sets (70:30)

Apply MinMax scaling to ensure non-negative feature values

Convert features into binary format for Bernoulli Naive Bayes

Train each Naive Bayes model separately

Evaluate predictions using:

Accuracy Score

Confusion Matrix

üîç Key Learning Points

Understanding the probabilistic foundation of Naive Bayes

Observing how data distribution affects model performance

Comparing different Naive Bayes variants on continuous data

Recognizing that certain Naive Bayes types are better suited for specific data formats

üìä Observations

Since the Breast Cancer dataset contains continuous numerical features, some Naive Bayes variants may not perform as optimally as models designed for continuous distributions. This experiment highlights the importance of selecting the correct model based on data characteristics.

üìå Topics Covered

Linear Regression

K-Nearest Neighbors (KNN)

Feature Selection Methods

Cross-Validation

Hyperparameter Tuning

Support Vector Machines (SVM)

Classification Metrics

Confusion Matrix Evaluation

üß∞ Tools & Libraries

Python

NumPy

Pandas

Scikit-learn

Matplotlib

Seaborn
